{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import vcf\n",
    "import sys\n",
    "import os\n",
    "import io\n",
    "\n",
    "\"\"\"\n",
    "    Merge vcf files, format for downstream  and filters homopolymers and seg. dupl STRs. \n",
    "    Output is a vcf file to be indexed with tabix\n",
    "    Usage:\n",
    "        STR_filter.py --vcf VCFs --homopolymers --seg_dup --hrun --hwe 0.1 --call_rate --heterozygosty 0.3  --out Filtered_STRs.vcf   \n",
    "\"\"\"\n",
    "\n",
    "SEGDUP=\"/storage/resources/dbase/human/hg19/hg19_segmentalduplications.bed\"\n",
    "HRUN = \"/storage/resources/dbase/human/hg19/hg19.hipstr_reference_hrun.bed\"\n",
    "OUTPUTFILE = \"\"\n",
    "\n",
    "HOM = True\n",
    "SeD = True\n",
    "HRN = True\n",
    "HWE = 0.05\n",
    "ClR = 0.8\n",
    "HETZYG = 0.3\n",
    "\n",
    "def PROGRESS(msg):\n",
    "    sys.stderr.write(\"%s\\n\"%msg.strip())\n",
    "\n",
    "def removehomopolymers(Frame):\n",
    "    cleanF=Frame.loc[Frame[\"UNIT\"]!=1]\n",
    "    return(cleanF)\n",
    "\n",
    "def removeoverlap(Frame, feat ):\n",
    "    L=list(set(list(Frame['CHROM'])))\n",
    "    fragments=[]\n",
    "    t=0\n",
    "    for C in L:\n",
    "        X = Frame.loc[Frame['CHROM']==C]\n",
    "        Y = feat.loc[feat['CHROM']=='chr'+str(C)]\n",
    "        X['POS'] = X[\"POS\"].astype(int)\n",
    "        X['END'] = X[\"END\"].astype(int)\n",
    "        for i in range(len(list(Y.index))):\n",
    "            start = list(Y['START'])[i]\n",
    "            end = list(Y['END'])[i]\n",
    "            X2 = X.loc[(X[\"END\"]<=start) | (X[\"POS\"]>=end)]\n",
    "            X = 0; X = X2\n",
    "        fragments.append(X2.sort_values('POS'))\n",
    "        print(C,'\\t',X.shape)\n",
    "    result = pd.concat(fragments)\n",
    "    return(result)\n",
    "   \n",
    "def removelowcallrate(Frame): \n",
    "    Frame['Count0'] = Frame.isnull().sum(axis=1)\n",
    "    Frame['Count1'] = Frame.isin({'./.:.'}).sum(1)\n",
    "    Frame['New'] = 650 - Frame['Count0']                     #650 samples\n",
    "    result = Frame.loc[Frame['Count1']<Frame['New']*0.2]     #Call rate 80%\n",
    "    del result['Count0']\n",
    "    del result['Count1']\n",
    "    del Table['New']\n",
    "    retun (result)\n",
    "    \n",
    "def GetLocusStats(record, samples=[]):\n",
    "    hwe_p = 0\n",
    "    het = 0\n",
    "    # Get genotypes, allele frequencies\n",
    "    allele_counts = {}\n",
    "    obs_het = 0\n",
    "    obs_hom = 0\n",
    "    total = 0\n",
    "    for sample in record:\n",
    "        if len(samples)>0 and sample.sample not in samples: continue\n",
    "        if sample[\"GB\"] == \".\" or sample[\"GB\"] == None: continue\n",
    "        gt = map(int, sample[\"GB\"].split(\"|\"))\n",
    "        if gt[0] == gt[1]: obs_hom += 1\n",
    "        else:\n",
    "            obs_het += 1\n",
    "        total += 1\n",
    "        for al in gt:\n",
    "            allele_counts[al] = allele_counts.get(al, 0) + 1\n",
    "    # Get Allele frequencies\n",
    "    allele_freqs = {}\n",
    "    for key in allele_counts.keys():\n",
    "        allele_freqs[key] = allele_counts[key]*1.0/sum(allele_counts.values())\n",
    "    # Get expected num homs/hets\n",
    "    exp_hom_frac = 0\n",
    "    for al in allele_freqs.keys():\n",
    "        exp_hom_frac += allele_freqs[al]**2\n",
    "    # Binomial test for HWE\n",
    "    hwe_p = scipy.stats.binom_test(obs_het, n=obs_het+obs_hom, p=1-exp_hom_frac)\n",
    "    # Compute heterozygosity\n",
    "    het = 1-sum([allele_freqs[al]**2 for al in allele_freqs.keys()])\n",
    "    # Get mean allele length\n",
    "    mean_allele = sum([al*allele_freqs[al] for al in allele_freqs])\n",
    "    return (hwe_p, het, mean_allele,obs_het+obs_hom)\n",
    "\n",
    "def getper(a, infofield):\n",
    "    a = a.split(\";\")\n",
    "    b =[b.split(\"=\")[1] for b in a if infofield in b]\n",
    "    return(b[0])\n",
    "\n",
    "def addheader():\n",
    "    header = \"\\n\".join(['##INFO=<ID=HWE,Number=1,Type=Float,Description=\"HWE pvalue genotype frequencies not as expected\">',\n",
    "            '##INFO=<ID=HET,Number=1,Type=Float,Description=\"Heterozygosity\">',\n",
    "            '##INFO=<ID=CCOUNT,Number=1,Type=Float,Description=\"Number of samples with genotype information\">',\n",
    "            '##FILTER=<ID=HET,Description=\"Heterozygosity less than '+str(HETZYG)+'\">',\n",
    "            '##FILTER=<ID=HRUN,Description=\"Hrun greater than -1\">',\n",
    "            '##FILTER=<ID=HWE,Description=\"HWE less than '+str(HWE)+'\">',\n",
    "            '##FILTER=<ID=CALLRATE,Description=\"Callrate less than '+str(ClR)+'\">',\n",
    "            '##FILTER=<ID=HOM_POLY,Description=\"Homopolymer locus\">',\n",
    "            '##FILTER=<ID=SEGDUP,Description=\"Locus in a segmental duplication\">\\n#'])\n",
    "    return(header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser(__doc__)\n",
    "    parser.add_argument(\"--vcf\", help=\"VCF file\", type=str, required=True)\n",
    "    parser.add_argument(\"--unrelated-samples\", help=\"Restrict to these samples to calculate popgen stats\", type=str, required=False)\n",
    "    parser.add_argument(\"--out\", help=\"Write filtered data to this file\", type=str, required=True)\n",
    "    parser.add_argument(\"--chrom\", help=\"Restrict to chromosome\", type=str, required=False)\n",
    "    parser.add_argument(\"--debug\", help=\"Print debug info\", action=\"store_true\")\n",
    "    parser.add_argument(\"--homopolymers\", help=\"Filters and Remove homopolymers STRs\", action=\"store_true\")\n",
    "    parser.add_argument(\"--seg_dup\", help=\"STRs overlapping segmental duplication will be removed\", action=\"store_true\")\n",
    "    parser.add_argument(\"--hrun\", help=\"Hexa and penta STRs with long homopolymer runs will be removed\", action=\"store_true\")\n",
    "    parser.add_argument(\"--hwe\", help=\"Remove locus not at hwe is pval >= 0.05 or otherwise specified \", type=float, required=False)\n",
    "    parser.add_argument(\"--call_rate\", help=\"Remove locus with call rate <= 80%% or otherwise specified \", type=float, required=False)\n",
    "    parser.add_argument(\"--heterozygosity\", help=\"Remove locus with low heterozygosity <=0.3 or otherwise specified \", type=float, required=False)\n",
    "\n",
    "#Input variables\n",
    "    args = parser.parse_args()\n",
    "    VCF = args.vcf\n",
    "    if args.chrom:\n",
    "        if 'chr' in args.chrom:\n",
    "            CH=args.chrom[3:]\n",
    "        else:\n",
    "            CH=args.chrom\n",
    "    HOM = args.homopolymers\n",
    "    SeD = args.seg_dup\n",
    "    HRN = args.hrun\n",
    "    HWE = args.hwe\n",
    "    ClR = args.call_rate\n",
    "    if args.heterozygosity:\n",
    "        try:\n",
    "            HETZYG = float(args.heterozygosity)\n",
    "        except:\n",
    "            HETZYG = 0.3\n",
    "    if args.unrelated_samples:\n",
    "        samples = [item.strip() for item in open(args.unrelated_samples, \"r\").readlines()]\n",
    "    else:\n",
    "        sample = []\n",
    "    OUTPUTFILE = args.out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Setup\n",
    "    PROGRESS('Starting ... ')\n",
    "    with open(VCF, 'r') as f:\n",
    "        lines = [l for l in f if not l.startswith('##')] \n",
    "        Head = [l for l in f if l.startswith('##')]\n",
    "    with open(OUTPUTFILE, 'w') as f:\n",
    "        f.write('\\n'.join(Head))\n",
    "               \n",
    "    Table = pd.read_table( io.BytesIO(str.join(os.linesep, lines)), dtype={'#CHROM': str, 'POS': int, 'ID': str, 'REF': str, 'ALT': str, 'QUAL': str, 'FILTER': str, 'INFO': str}).rename(columns={'#CHROM': 'CHROM'})\n",
    "        \n",
    "    vcf_reader = vcf.Reader(filename=VCF)\n",
    "    N=len(vcf_reader.samples)*ClR\n",
    "    \n",
    "    if args.chrom:\n",
    "        Table = Table.loc[Table['CHROM']==CH]\n",
    "        vcf_reader = vcf.Reader(filename=VCF).fetch(CH)\n",
    "    PROGRESS('File opened... '+str(Table.shape))\n",
    "    \n",
    "    Table['REF'] = [x.split(',')[0] for x in list(Table['REF'])]\n",
    "    Table['UNIT'] = [int(getper(x, 'PERIOD')) for x in list(Table['INFO']) ]\n",
    "    Table['END'] = [int(getper(x,'END')) for x in list(Table['INFO'])]    \n",
    "    PROGRESS(\"unit & end\"+str(Table.shape))\n",
    "    \n",
    "    Table[\"stats\"]=[GetLocusStats(record) for record in vcf_reader]\n",
    "    Table[\"hwepval\"] = [x[0] for x in list(Table['stats'])]\n",
    "    Table[\"Hetzyg\"] = [x[1] for x in list(Table['stats'])]\n",
    "    Table[\"mean_al\"] = [x[2] for x in list(Table['stats'])]\n",
    "    Table[\"CallCounts\"]=[x[3] for x in list(Table['stats'])]               \n",
    "    PROGRESS('Additional details added... '+str(Table.shape[0]))\n",
    "    \n",
    "# low call rate STRs and homopolymers\n",
    "# low heterozygosity locus            \n",
    "# locus not in HWE\n",
    "\n",
    "\n",
    "    if HOM:\n",
    "        Table[\"FILTER\"] = np.where(Table[\"UNIT\"] !=1, Table[\"FILTER\"], Table[\"FILTER\"]+\" HOM_POLY\")\n",
    "    ### Create HOM only file with ==1 instead of !=1\n",
    "\n",
    "    if ClR:     \n",
    "        Table[\"FILTER\"] = np.where(Table[\"CallCounts\"] >= N, \"\", \"CALLRATE\")\n",
    "    \n",
    "    if HWE:\n",
    "        Table[\"FILTER\"] = np.where(Table[\"hwepval\"] >=HWE, Table[\"FILTER\"], Table[\"FILTER\"]+\" HWE\")\n",
    "        \n",
    "    if HETZYG:\n",
    "        Table[\"FILTER\"] = np.where(Table[\"Hetzyg\"] >=HETZYG, Table[\"FILTER\"], Table[\"FILTER\"]+\" HET\")\n",
    "        \n",
    "    PROGRESS('Call rate, homopolymers, hwe, heterozyg. Filters added... '+str(Table.shape[0]))    \n",
    "    \n",
    "#Seg dup\n",
    "    if SeD:\n",
    "        Seg_dup = pd.read_csv(SEGDUP, sep='\\t', header=None)\n",
    "        Seg_dup.columns = ['CHROM', 'START','END','OTHERS','INFO','STRAND']\n",
    "        Table_c = removeoverlap(Table, Seg_dup)\n",
    "        Table[\"FILTER\"] = np.where(Table[\"ID\"].isin(list(Table_c['ID'])), Table[\"FILTER\"], Table[\"FILTER\"]+\" SEGDUP\")    \n",
    "    PROGRESS('Segmental Duplication filter added... '+str(Table.shape))\n",
    "# Hrun\n",
    "    if HRN:\n",
    "        X = pd.read_csv(HRUN,sep='\\t', header=None)\n",
    "        X.columns = ['CHROM', 'START','END','Unitsize','maxrun']\n",
    "        X1 = X.loc[X['Unitsize'].isin([5,6])]\n",
    "        hrun = X1.loc[X1['maxrun']>X1['Unitsize']]\n",
    "        Table_c = removeoverlap(Table, hrun)\n",
    "        Table[\"FILTER\"] = np.where(Table[\"ID\"].isin(list(Table_c['ID'])), Table[\"FILTER\"], Table[\"FILTER\"]+\" HRUN \")\n",
    "    PROGRESS('Penta and hexa with homopolymer runs ... '+str(Table.shape))\n",
    "\n",
    "    \n",
    "#Reformat INFO, FILTER    \n",
    "    Table[\"info2\"] = ';HWE='+Table[\"hwepval\"].astype(str) +';HET=' +Table[\"Hetzyg\"].astype(str)+ ';CCOUNT='+ Table[\"CallCounts\"].astype(str)  \n",
    "    Table['INFO'] = Table['INFO']+Table['info2']\n",
    "    Table['FILTER'] = np.where(Table[\"FILTER\"]!='', Table[\"FILTER\"], \"PASS\")\n",
    "    C = [';'.join(s.split()) for s in list(Table['FILTER'])]\n",
    "    Table['FILTER'] = C\n",
    "    PROGRESS('Fields formatted ... ')\n",
    "    \n",
    "#Clean up    \n",
    "    del Table['stats']\n",
    "    del Table['hwepval']\n",
    "    del Table['mean_al']\n",
    "    del Table['Hetzyg']\n",
    "    del Table['CallCounts']\n",
    "    del Table['UNIT']\n",
    "    del Table['END']\n",
    "    del Table['info2']\n",
    "    C = ['-'.join(x.split('-')[:2]) for x in list(Table.columns)]\n",
    "    Table.columns = C\n",
    "    C = Table.loc[Table['FILTER']=='PASS']\n",
    "    PROGRESS('Cleaned up. Saving to file ... \\n\\t'+str(C.shape[0])+' passed all filters...')\n",
    "\n",
    "#Package and save vcf\n",
    "    PROGRESS(\"Saving to file\")\n",
    "    command = \"grep '^##' \"+VCF\n",
    "    vcfheader = subprocess.check_output(command, shell=True)\n",
    "    f=open('tmp','w')\n",
    "    f.write(vcfheader.decode('utf-8'))\n",
    "    f.write(addheader())\n",
    "    f.close()\n",
    "    Table = Table.sort_values(['CHROM','POS'])\n",
    "    Table.to_csv('table.tab',sep='\\t',index=None)\n",
    "    command = \"cat tmp table.tab >\"+OUTPUTFILE \n",
    "    MG = subprocess.check_output(command, shell=True)\n",
    "    command = \"rm table.tab\"\n",
    "    MG = subprocess.check_output(command, shell=True)\n",
    "    command = \"rm tmp\"\n",
    "    MG = subprocess.check_output(command, shell=True)\n",
    "#compress and index vcf \n",
    "    PROGRESS(\"Indexing\")\n",
    "    command = \"bgzip -c \"+ OUTPUTFILE +\" > \"+OUTPUTFILE+'.gz'\n",
    "    MG = subprocess.check_output(command, shell=True)\n",
    "    command = \"tabix -p vcf \"+ OUTPUTFILE +'.gz '\n",
    "    MG = subprocess.check_output(command, shell=True)\n",
    "\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
