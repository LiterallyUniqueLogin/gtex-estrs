{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import vcf\n",
    "import io\n",
    "from datetime import datetime\n",
    "\"\"\"\n",
    "    Merge vcf files, format for downstream  and filters homopolymers and seg. dupl STRs. \n",
    "    Output is a vcf file to be indexed with tabix\n",
    "    Usage:\n",
    "        STR_filter.py --vcf VCFs --remove_homopolymers --remove_seg_dup --hprun  --out Filtered_STRs.vcf\n",
    "        \n",
    "\"\"\"\n",
    "\n",
    "SEGDUP=\"/storage/resources/dbase/human/hg19/hg19_segmentalduplications.bed\"\n",
    "HRUN = \"/storage/resources/dbase/human/hg19/hg19.hipstr_reference_hrun.bed\"\n",
    "VCF = \"/storage/szfeupe/Runs/650GTEx_estr/Merged_all.vcf\"\n",
    "VCF1 = \"/storage/szfeupe/Runs/650GTEx_estr/VCFs/Filtered_SRR2157199_hipstr.vcf\"\n",
    "OUTPUTFILE = \"/storage/szfeupe/Runs/650GTEx_estr/Erged_all.vcf.gz\"\n",
    "\n",
    "HOM = True\n",
    "SeD = True\n",
    "HRN = True\n",
    "HWE = 0.05\n",
    "ClR = 0.8*650\n",
    "HETZYG = 0.3\n",
    "\n",
    "def removehomopolymers(Frame):\n",
    "    cleanF=Frame.loc[Frame[\"UNIT\"]!='1']\n",
    "    return(cleanF)\n",
    "\n",
    "def removeoverlap(Frame, feat ):\n",
    "    L=list(set(list(Frame['CHROM'])))\n",
    "    fragments=[]\n",
    "    t=0\n",
    "    for C in L:\n",
    "        X = Frame.loc[Frame['CHROM']==C]\n",
    "        Y = feat.loc[feat['CHROM']=='chr'+str(C)]\n",
    "        X['POS'] = X[\"POS\"].astype(int)\n",
    "        X['END'] = X[\"END\"].astype(int)\n",
    "        for i in range(len(list(Y.index))):\n",
    "            start = list(Y['START'])[i]\n",
    "            end = list(Y['END'])[i]\n",
    "            X2 = X.loc[(X[\"END\"]<=start) | (X[\"POS\"]>=end)]\n",
    "            X = 0; X = X2\n",
    "        fragments.append(X2.sort_values('POS'))\n",
    "        print(C,'\\t',X.shape)\n",
    "    result = pd.concat(fragments)\n",
    "    return(result)\n",
    "   \n",
    "def removelowcallrate(Frame): \n",
    "    Frame['Count0'] = Frame.isnull().sum(axis=1)\n",
    "    Frame['Count1'] = Frame.isin({'./.:.'}).sum(1)\n",
    "    Frame['New'] = 650 - Frame['Count0']                     #650 samples\n",
    "    result = Frame.loc[Frame['Count1']<Frame['New']*0.2]     #Call rate 80%\n",
    "    del result['Count0']\n",
    "    del result['Count1']\n",
    "    del Table['New']\n",
    "    retun (result)\n",
    "    \n",
    "def GetLocusStats(record, samples=[]):\n",
    "    hwe_p = 0\n",
    "    het = 0\n",
    "    # Get genotypes, allele frequencies\n",
    "    allele_counts = {}\n",
    "    obs_het = 0\n",
    "    obs_hom = 0\n",
    "    total = 0\n",
    "    for sample in record:\n",
    "        if len(samples)>0 and sample.sample not in samples: continue\n",
    "        if sample[\"GB\"] == \".\" or sample[\"GB\"] == None: continue\n",
    "        gt = list(map(int, sample[\"GB\"].split(\"|\")))\n",
    "        if gt[0] == gt[1]: obs_hom += 1\n",
    "        else:\n",
    "            obs_het += 1\n",
    "        total += 1\n",
    "        for al in gt:\n",
    "            allele_counts[al] = allele_counts.get(al, 0) + 1\n",
    "    # Get Allele frequencies\n",
    "    allele_freqs = {}\n",
    "    for key in allele_counts.keys():\n",
    "        allele_freqs[key] = allele_counts[key]*1.0/sum(allele_counts.values())\n",
    "    # Get expected num homs/hets\n",
    "    exp_hom_frac = 0\n",
    "    for al in allele_freqs.keys():\n",
    "        exp_hom_frac += allele_freqs[al]**2\n",
    "    # Binomial test for HWE\n",
    "    hwe_p = scipy.stats.binom_test(obs_het, n=obs_het+obs_hom, p=1-exp_hom_frac)\n",
    "    # Compute heterozygosity\n",
    "    het = 1-sum([allele_freqs[al]**2 for al in allele_freqs.keys()])\n",
    "    # Get mean allele length\n",
    "    mean_allele = sum([al*allele_freqs[al] for al in allele_freqs])\n",
    "    return (hwe_p, het, mean_allele,obs_het+obs_hom)\n",
    "\n",
    "def getper(a, infofield):\n",
    "    a = a.split(\";\")\n",
    "    b =[b.split(\"=\")[1] for b in a if infofield in b]\n",
    "    return(b[0])\n",
    "\n",
    "\n",
    "def addheader():\n",
    "    header = \"\\n\".join(['##INFO=<ID=HWE,Number=1,Type=Float,Description=\"HWE pvalue genotype frequencies not as expected\">',\n",
    "            '##INFO=<ID=HET,Number=1,Type=Float,Description=\"Heterozygosity\">',\n",
    "            '##INFO=<ID=CCOUNT,Number=1,Type=Float,Description=\"Number of samples with genotype information\">',\n",
    "            '##FILTER=<ID=HET,Description=\"Heterozygosity less than '+str(HETZYG)+'\">',\n",
    "            '##FILTER=<ID=HRUN,Description=\"Hrun greater than -1\">',\n",
    "            '##FILTER=<ID=HWE,Description=\"HWE less than '+str(HWE)+'\">',\n",
    "            '##FILTER=<ID=CALLRATE,Description=\"Callrate less than '+str(ClR)+'\">',\n",
    "            '##FILTER=<ID=HOM_POLY,Description=\"Homopolymer locus\">',\n",
    "            '##FILTER=<ID=SEGDUP,Description=\"Locus in a segmental duplication\">\\n#'])\n",
    "    return(header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Table = pd.read_table( io.BytesIO(str.join(os.linesep, lines)), dtype={'#CHROM': str, 'POS': int, 'ID': str, 'REF': str, 'ALT': str, 'QUAL': str, 'FILTER': str, 'INFO': str}).rename(columns={'#CHROM': 'CHROM'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK (23619, 661)\n",
      "unit (23619, 662)\n",
      "unit (23619, 662)\n",
      "End (23619, 662)\n",
      "Stats (23619, 663)\n",
      "Stats... (23619, 667)\n"
     ]
    }
   ],
   "source": [
    "Table = pd.read_csv('/storage/szfeupe/Runs/650GTEx_estr/table.tab', sep='\\t')########\n",
    "print(\"OK\",Table.shape) ############\n",
    "Table['REF'] = [x.split(',')[0] for x in list(Table['REF'])]\n",
    "Table['UNIT'] = [int(getper(x, 'PERIOD')) for x in list(Table['INFO']) ]\n",
    "print(\"unit\",Table.shape)\n",
    "Table['END'] = [int(getper(x,'END')) for x in list(Table['INFO'])]\n",
    "print(\"unit\",Table.shape)\n",
    "VCF = \"/storage/szfeupe/Runs/650GTEx_estr/chr22.vcf.gz\"###############\n",
    "print(\"End\",Table.shape)\n",
    "vcf_reader = vcf.Reader(filename=VCF)\n",
    "#Table[\"stats\"]=[GetLocusStats(record) for record in vcf_reader]\n",
    "Table[\"stats\"]=[GetLocusStats(record) for record in vcf_reader.fetch('22')] ########\n",
    "print(\"Stats\",Table.shape)\n",
    "Table[\"hwepval\"] = [x[0] for x in list(Table['stats'])]\n",
    "Table[\"Hetzyg\"] = [x[1] for x in list(Table['stats'])]\n",
    "Table[\"mean_al\"] = [x[2] for x in list(Table['stats'])]\n",
    "Table[\"CallCounts\"]=[x[3] for x in list(Table['stats'])]\n",
    "\n",
    "N=len(vcf.Reader(filename=VCF).samples)*.8\n",
    "Table[\"FILTER\"] = np.where(Table[\"CallCounts\"] > N, \"\", \"CALLRATE\")\n",
    "Table[\"FILTER\"] = np.where(Table[\"UNIT\"] !=1, Table[\"FILTER\"], Table[\"FILTER\"]+\" HOM_POLY\")\n",
    "Table[\"FILTER\"] = np.where(Table[\"hwepval\"] <0.01, Table[\"FILTER\"], Table[\"FILTER\"]+\" HWE\")\n",
    "Table[\"FILTER\"] = np.where(Table[\"Hetzyg\"] >0.3, Table[\"FILTER\"], Table[\"FILTER\"]+\" HET\")\n",
    "\n",
    "\n",
    "Table = Table.rename(columns={'#CHROM': 'CHROM'})\n",
    "print(\"Stats...\", Table.shape)\n",
    "#seg dup\n",
    "if SeD:\n",
    "    Seg_dup = pd.read_csv(SEGDUP, sep='\\t', header=None)\n",
    "    Seg_dup.columns = ['CHROM', 'START','END','OTHERS','INFO','STRAND']\n",
    "    Table_c = removeoverlap(Table, Seg_dup)\n",
    "    Table[\"FILTER\"] = np.where(Table[\"ID\"].isin(list(Table_c['ID'])), Table[\"FILTER\"], Table[\"FILTER\"]+\" SEGDUP\")    \n",
    "\n",
    "print(\"Segdup ... \", Table.shape)\n",
    "# hrun\n",
    "if HRN:\n",
    "    X = pd.read_csv(HRUN,sep='\\t', header=None)\n",
    "    X.columns = ['CHROM', 'START','END','Unitsize','maxrun']\n",
    "    X1 = X.loc[X['Unitsize'].isin([5,6])]\n",
    "    hrun = X1.loc[X1['maxrun']>X1['Unitsize']]\n",
    "    Table_c = removeoverlap(Table, hrun)\n",
    "    Table[\"FILTER\"] = np.where(Table[\"ID\"].isin(list(Table_c['ID'])), Table[\"FILTER\"], Table[\"FILTER\"]+\" HRUN \")\n",
    "print(\"Hrun ... \",Table.shape)\n",
    "\n",
    "Table[\"info2\"] = ';HWE='+Table[\"hwepval\"].astype(str) +';HET='+Table[\"Hetzyg\"].astype(str)+';CCOUNT='+Table[\"CallCounts\"].astype(str)  \n",
    "Table['INFO'] = Table['INFO']+Table['info2']\n",
    "Table['FILTER'] = np.where(Table[\"FILTER\"]!='', Table[\"FILTER\"], \"PASS\")\n",
    "C = [';'.join(s.split()) for s in list(Table['FILTER'])]\n",
    "Table['FILTER'] = C\n",
    "print(\"Format ... \",Table.shape)\n",
    "\n",
    "del Table['stats']\n",
    "del Table['hwepval']\n",
    "del Table['mean_al']\n",
    "del Table['Hetzyg']\n",
    "del Table['CallCounts']\n",
    "del Table['UNIT']\n",
    "del Table['END']\n",
    "del Table['info2']\n",
    "print(\"Clean ... \",Table.shape)\n",
    "Table.loc[Table['FILTER']=='PASS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUTFILE = \"/storage/szfeupe/Runs/650GTEx_estr/CHR10Merged_all.vcf\"\n",
    "command = \"grep '^##' \"+VCF\n",
    "vcfheader = subprocess.check_output(command, shell=True)\n",
    "f=open('tmp','w')\n",
    "f.write(vcfheader.decode('utf-8'))\n",
    "f.write(addheader())\n",
    "f.close()\n",
    "Table = Table.sort_values(['CHROM','POS'])\n",
    "Table.to_csv('table.tab',sep='\\t',index=None)\n",
    "command = \"cat tmp table.tab >\"+OUTPUTFILE \n",
    "MG = subprocess.check_output(command, shell=True)\n",
    "command = \"rm table.tab\"\n",
    "MG = subprocess.check_output(command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8987106883659556"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "65383/72752"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
